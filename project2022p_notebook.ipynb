{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quarcs-lab/project2022p/blob/master/project2022p_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5MA1guiNFT3"
      },
      "source": [
        "<center>\n",
        "<h1> Exploring economic activity from outer space: A Python notebook for processing and analyzing satellite nighttime lights </h1>\n",
        "<!-- <h3> Carlos Mendez<sup>1</sup> Ayush Patnaik<sup>2</sup>\n",
        "\n",
        "</h3>\n",
        "</center>\n",
        "<center>\n",
        "<h3>\n",
        "1. Nagoya University\n",
        "2. xKDR Forum\n",
        "</h3>\n",
        "</center> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Erh4ZObGNFT5"
      },
      "source": [
        "<center> <h2> Abstract </h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ij_h7Z4mNFT6"
      },
      "source": [
        "Nighttime lights (NTL) data are widely recognized as a useful proxy for monitoring national, subnational, and supranational economic activity. These data offer advantages over traditional economic indicators such as GDP, including greater spatial granularity, timeliness, lower cost, and comparability between regions regardless of statistical capacity or political interference. However, despite these benefits, the use of NTL data in regional science has been limited. This is in part due to the lack of accessible methods for processing and analyzing satellite images. To address this issue, this paper presents a user-friendly geocomputational notebook that illustrates how to process and analyze satellite NTL images. First, the notebook introduces a cloud-based Python environment for visualizing, analyzing, and transforming raster satellite images into tabular data. Next, it presents interactive tools to explore the space-time patterns of the tabulated data. Finally, it describes methods for evaluating the usefulness of NTL data in terms of their cross-sectional predictions, time-series predictions, and regional inequality dynamics.\n",
        "\n",
        "**Keywords:** satellite nighttime lights, regional income, zonal statistics, exploratory data analysis (EDA), panel data analysis, inequality dynamics, Jupyter notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73aXdUDANFT6"
      },
      "source": [
        "## 1. Introduction\n",
        "\n",
        "Nighttime lights (NTL) data have become a widely recognized proxy to monitor economic activity at the national, subnational, and supranational levels (Chen, Nordhaus, 2011; Henderson et al., 2012; Sutton et al., 2007). The use of NTL data can offer considerable advantages over traditional economic indicators, such as GDP. For example, NTL data provide greater spatial granularity, are more timely, and are less costly to construct than GDP. Furthermore, NTL data are comparable between multiple regions, regardless of differences in statistical capacity, political interference, or informal activities.\n",
        "\n",
        "Despite their potential benefits, the latest NTL data products (Elvidge et al., 2017; Li et al., 2020; Rom ́an et al., 2018) have had limited use in the regional science literature. One plausible reason for this limitation is the lack of accessible methods for processing and analyzing satellite images. Specifically, the processing of large raster-based satellite images into tabular data has made it difficult for researchers to use the latest satellite data products. To address this issue, we introduce a geocomputational notebook that provides a step-by-step guide on how to process and analyze recent satellite NTL images.\n",
        "\n",
        "The notebook begins by introducing a cloud-based Python environment for visualizing and transforming raster images into tabular data. The notebook then presents interactive tools to explore the space-time patterns of the tabulated data. These tools allow researchers to better understand both the spatial distribution and the temporal trends of NTL data. To develop a sense of the informational content of NTL, the space-time patterns of GDP are also presented. Finally, the notebook illustrates methods for evaluating the usefulness of NTL data in terms of cross-sectional predictions, time-series predictions, and regional inequality dynamics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxJMWjtJNFT7"
      },
      "source": [
        "## 2. Cloud-based environment\n",
        "\n",
        "Modern computational notebooks allow us to present code in conjunction with descriptive text, equations, visualizations, and tables in a single document (Rowe et al., 2020). The use of such notebooks greatly enhances the reproducibility and transparency of scientific research. Although computational notebooks are a step forward, a major bottleneck remains in the reproducibility of the computational environment that is used to produce research results. Especially for geospatial analysis, a notebook user still needs to download, install, and manage numerous computational libraries and their dependencies.\n",
        "\n",
        "Cloud-based environments such as Google's [Colab](https://colab.research.google.com/) or [Deepnote](https://deepnote.com/) offer a solution to the reproducible-environment problem. They offer notebooks running on cloud computers, which can be duplicated with a single click.\n",
        "\n",
        "To process and analyze satellite images in a fully reproducible cloud-based environment, we host a [notebook](https://colab.research.google.com/drive/1UsukjQQ5lQNvpWTaIXcnyB6oXX7ne-i3?usp=sharing) on Colab. This cloud-based environment can be easily duplicated, run and extended after logging in with a Google account. The notebook can also be downloaded and run and edited locally.\n",
        "\n",
        "This environment, running Python 3.9, requires the following libraries along with their associated dependencies:\n",
        "\n",
        "| Package         | Version | Description                                                                                        |\n",
        "|------------------|-------------------|----------------------------------------------------------------------------------------------------|\n",
        "| numpy      | 1.23.5            | Library that provides functions for mathematical operations and handling arrays                         |\n",
        "| pandas     | 1.5.3             | Library that provides a data frame class and functions to manipulate data frames                         |\n",
        "| geopandas   | 0.13.2            | Library that helps work with spatial data                                                               |\n",
        "| matplotlib  | 3.7.1 | Plotting library, including plotting functions                                                       |\n",
        "| contextily  | 1.3.0             | Library that helps to add base layers to maps                                                       |\n",
        "| rasterio    | 1.3.9             | Library for raster data processing                                                                  |\n",
        "| linearmodels | 4.27             | Library for linear regressions, including panel data analysis                                      |\n",
        "| inequality | 1.0.0             | Library that provides methods for measuring inequality                                               |\n",
        "| os          |                   | Operating system interface                                                                          |\n",
        "| requests   | 2.31.0            | HTTP library for making requests in Python                                                         |\n",
        "| glob        |                   | File path pattern matching                                                                          |\n",
        "| shutil     |                   | High-level file operation utilities                                                                |\n",
        "| bs4        |                   | BeautifulSoup library for parsing HTML and XML                                                      |\n",
        "| json        |                   | Library for working with JSON data                                                                 |\n",
        "| gzip        |                   | Library for compressing and decompressing files using the gzip format                                |\n",
        "| plotly |          5.15.0         | High-level library for creating interactive visualizations with Plotly                              |                                               |\n",
        "| cufflinks   | 0.17.3            | Productivity Tools for Plotly + Pandas                                                             |\n",
        "| mpl_toolkits |                   | Tool for advanced axes layout in Matplotlib                                                         |                                                 |\n",
        "| linearmodels |      4.27             | Library for performing linear regressions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZZPcWA8NsRJ",
        "outputId": "3361486d-9013-403c-f9ca-83289a68485f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: pandas==1.5.3 in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: geopandas==0.13.2 in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: matplotlib==3.7.1 in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Collecting contextily==1.3.0\n",
            "  Downloading contextily-1.3.0-py3-none-any.whl (16 kB)\n",
            "Collecting rasterio==1.3.9\n",
            "  Downloading rasterio-1.3.9-cp310-cp310-manylinux2014_x86_64.whl (20.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: folium==0.14.0 in /usr/local/lib/python3.10/dist-packages (0.14.0)\n",
            "Collecting kaleido==0.2.1\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mapclassify==2.6.0\n",
            "  Downloading mapclassify-2.6.0-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting linearmodels==4.27\n",
            "  Downloading linearmodels-4.27-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting inequality==1.0.0\n",
            "  Downloading inequality-1.0.0.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cufflinks==0.17.3 in /usr/local/lib/python3.10/dist-packages (0.17.3)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: plotly==5.15.0 in /usr/local/lib/python3.10/dist-packages (5.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3) (2023.3.post1)\n",
            "Requirement already satisfied: fiona>=1.8.19 in /usr/local/lib/python3.10/dist-packages (from geopandas==0.13.2) (1.9.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from geopandas==0.13.2) (23.2)\n",
            "Requirement already satisfied: pyproj>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from geopandas==0.13.2) (3.6.1)\n",
            "Requirement already satisfied: shapely>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from geopandas==0.13.2) (2.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.1) (3.1.1)\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.10/dist-packages (from contextily==1.3.0) (2.3.0)\n",
            "Collecting mercantile (from contextily==1.3.0)\n",
            "  Downloading mercantile-1.2.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from contextily==1.3.0) (1.3.2)\n",
            "Requirement already satisfied: xyzservices in /usr/local/lib/python3.10/dist-packages (from contextily==1.3.0) (2023.10.1)\n",
            "Collecting affine (from rasterio==1.3.9)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio==1.3.9) (23.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio==1.3.9) (2023.11.17)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio==1.3.9) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio==1.3.9) (0.7.2)\n",
            "Collecting snuggs>=1.4.1 (from rasterio==1.3.9)\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio==1.3.9) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio==1.3.9) (67.7.2)\n",
            "Requirement already satisfied: branca>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from folium==0.14.0) (0.7.0)\n",
            "Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from folium==0.14.0) (3.1.3)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from mapclassify==2.6.0) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from mapclassify==2.6.0) (1.2.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from mapclassify==2.6.0) (3.2.1)\n",
            "Requirement already satisfied: statsmodels>=0.11 in /usr/local/lib/python3.10/dist-packages (from linearmodels==4.27) (0.14.1)\n",
            "Collecting property-cached>=1.6.3 (from linearmodels==4.27)\n",
            "  Downloading property_cached-1.6.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting mypy-extensions>=0.4 (from linearmodels==4.27)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: Cython>=0.29.21 in /usr/local/lib/python3.10/dist-packages (from linearmodels==4.27) (3.0.8)\n",
            "Collecting pyhdfe>=0.1 (from linearmodels==4.27)\n",
            "  Downloading pyhdfe-0.2.0-py3-none-any.whl (19 kB)\n",
            "Collecting formulaic~=0.3.2 (from linearmodels==4.27)\n",
            "  Downloading formulaic-0.3.4-py3-none-any.whl (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.2/68.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setuptools-scm<7.0.0,>=6.4.2 (from linearmodels==4.27)\n",
            "  Downloading setuptools_scm-6.4.2-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from cufflinks==0.17.3) (1.16.0)\n",
            "Requirement already satisfied: colorlover>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from cufflinks==0.17.3) (0.3.0)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from cufflinks==0.17.3) (7.34.0)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from cufflinks==0.17.3) (7.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (2.0.7)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly==5.15.0) (8.2.3)\n",
            "Collecting astor>=0.8 (from formulaic~=0.3.2->linearmodels==4.27)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting interface-meta<2.0.0,>=1.2.0 (from formulaic~=0.3.2->linearmodels==4.27)\n",
            "  Downloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic~=0.3.2->linearmodels==4.27) (1.14.1)\n",
            "Collecting jedi>=0.16 (from ipython>=5.3.0->cufflinks==0.17.3)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->cufflinks==0.17.3) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->cufflinks==0.17.3) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->cufflinks==0.17.3) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->cufflinks==0.17.3) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->cufflinks==0.17.3) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->cufflinks==0.17.3) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->cufflinks==0.17.3) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->cufflinks==0.17.3) (4.9.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.0.0->cufflinks==0.17.3) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.0.0->cufflinks==0.17.3) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.0.0->cufflinks==0.17.3) (3.6.6)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.0.0->cufflinks==0.17.3) (3.0.9)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.9->folium==0.14.0) (2.1.4)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from setuptools-scm<7.0.0,>=6.4.2->linearmodels==4.27) (2.0.1)\n",
            "Requirement already satisfied: patsy>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.11->linearmodels==4.27) (0.5.6)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.10/dist-packages (from geopy->contextily==1.3.0) (2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->mapclassify==2.6.0) (3.2.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->cufflinks==0.17.3) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->cufflinks==0.17.3) (6.3.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.3.0->cufflinks==0.17.3) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.3.0->cufflinks==0.17.3) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->cufflinks==0.17.3) (0.2.13)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (6.5.5)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (5.7.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (5.9.2)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (0.18.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (0.19.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (1.0.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (4.1.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (0.2.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (0.9.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (4.19.2)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (21.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (0.32.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (0.17.1)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (1.7.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (0.5.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (1.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->cufflinks==0.17.3) (2.21)\n",
            "Building wheels for collected packages: inequality\n",
            "  Building wheel for inequality (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for inequality: filename=inequality-1.0.0-py3-none-any.whl size=11777 sha256=b71136d4351fafec35ebb230e16e9252964f4a76c7c8b0ae20230b97e7b770c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/f7/af/eb988b28568f650a2329b2b3e954019a1c3ceb084dae385b51\n",
            "Successfully built inequality\n",
            "Installing collected packages: kaleido, snuggs, setuptools-scm, property-cached, mypy-extensions, mercantile, jedi, interface-meta, astor, affine, rasterio, pyhdfe, inequality, mapclassify, formulaic, contextily, linearmodels\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed affine-2.4.0 astor-0.8.1 contextily-1.3.0 formulaic-0.3.4 inequality-1.0.0 interface-meta-1.3.0 jedi-0.19.1 kaleido-0.2.1 linearmodels-4.27 mapclassify-2.6.0 mercantile-1.2.1 mypy-extensions-1.0.0 property-cached-1.6.4 pyhdfe-0.2.0 rasterio-1.3.9 setuptools-scm-6.4.2 snuggs-1.4.7\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy==1.23.5 \\\n",
        "pandas==1.5.3 \\\n",
        "geopandas==0.13.2 \\\n",
        "matplotlib==3.7.1 \\\n",
        "contextily==1.3.0 \\\n",
        "rasterio==1.3.9 \\\n",
        "folium==0.14.0 \\\n",
        "kaleido==0.2.1 \\\n",
        "mapclassify==2.6.0 \\\n",
        "linearmodels==4.27 \\\n",
        "inequality==1.0.0 \\\n",
        "cufflinks==0.17.3 \\\n",
        "requests==2.31.0 \\\n",
        "plotly==5.15.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Af1KOFE4NFT7",
        "outputId": "9c39d1df-2c0a-45fa-f9b9-5ef79a13ee8c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.24.1.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np  # Library that provides functions for mathematical operations and handling arrays\n",
        "import pandas as pd  # Libaray that provides a data frame class and functions to manipulate data frames\n",
        "import geopandas as gpd  # Library that helps working with spatial data\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt  # Function for 2D plotting\n",
        "from matplotlib.gridspec import GridSpec\n",
        "from mpl_toolkits.axes_grid1 import (\n",
        "    make_axes_locatable,\n",
        ")  # Function to create a new axis on a plot\n",
        "\n",
        "import contextily as cx  # Library that helps adding OSM base layer to plots.\n",
        "\n",
        "import plotly.express as px  # Library for interactive plotting\n",
        "\n",
        "# Libraries to allow plotly to be offline and show plots in a jupyter notebook\n",
        "import plotly.io as pio\n",
        "import plotly.graph_objects as go\n",
        "import cufflinks as cf\n",
        "\n",
        "cf.go_offline()\n",
        "\n",
        "import rasterio  # Library for raster data processing\n",
        "from rasterio import plot as rioplot  # Function to plot raster data\n",
        "from rasterio.mask import (\n",
        "    mask,\n",
        ")  # Function for masking raster data using shapefile for zonal statistics\n",
        "\n",
        "# linearmodels library provides helps performing regressions\n",
        "from linearmodels import PooledOLS  # Function to perform pooled OLS regression\n",
        "from linearmodels import PanelOLS  # Function to perform OLS regression on panel data\n",
        "from linearmodels import BetweenOLS # Function to compute the between estimator of an OLS regression\n",
        "from linearmodels.panel.results import compare # Function compare results of an OLS regression\n",
        "\n",
        "import inequality  # Library that provides methods for measuring spatial inequality\n",
        "\n",
        "import os # Operating system interface\n",
        "import requests # HTTP library for making requests in Python\n",
        "import glob # File path pattern matching\n",
        "import shutil # High-level file operation utilities\n",
        "from bs4 import BeautifulSoup # BeautifulSoup library for parsing HTML and XML\n",
        "import json # Library for working with JSON data\n",
        "import gzip # Library for compressing and decompressing files using the gzip format"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set precision to 4\n",
        "pd.set_option('display.precision', 4)\n",
        "\n",
        "# Set max columns to 7\n",
        "pd.set_option('display.max_columns', 7)\n",
        "\n",
        "# Set max rows to 10\n",
        "pd.set_option('display.max_rows', 10)"
      ],
      "metadata": {
        "id": "44kryeKAXC99"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_latex_table(df, filepath, max_rows = None, max_cols = None):\n",
        "    truncated_df = pd.read_html(df.copy().round(4).to_html(index = False, max_rows=max_rows, max_cols=max_cols))[0]\n",
        "    print(truncated_df.astype(str).to_latex(index = False), file=open(filepath, \"w\"))"
      ],
      "metadata": {
        "id": "zFrT-wmxXHgC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ10rHDDNFT8"
      },
      "source": [
        "## 3. Data\n",
        "\n",
        "In this paper, we use three datasets: (1) satellite nighttime light images; (2) subnational\n",
        "income per capita; and (3) administrative boundaries for the states of India.\n",
        "\n",
        "### 3.1 Satellite nighttime light images\n",
        "\n",
        "There are two data sets for night lights that are widely used in the remote sensing literature. DMSP-OLS is an annual dataset that is available from 1992 to 2013. This was discontinued after the launch of Suomi-NPP which has the “Visible Infrared Imaging Radiometer Suite” (VIIRS) sensor with superior measurement capabilities. The two data sources are summarized in Table 1 and their differences are presented in detail in Elvidge et al. (2013).\n",
        "\n",
        "  <table style=\"width:100%\">\n",
        "    <tr>\n",
        "      <th>Dataset</th>\n",
        "      <th>Source</th>\n",
        "      <th>Period</th>\n",
        "      <th>Frequency</th>\n",
        "      <th>Resolution</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td><a href=\"https://ngdc.noaa.gov/eog/dmsp/downloadV4composites.html\">DMSP</a></td>\n",
        "      <td>DoD-NOAA</td>\n",
        "      <td>1992 - 2013</td>\n",
        "      <td>Annual</td>\n",
        "      <td>30 arc seconds</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td><a href=\"https://ngdc.noaa.gov/eog/viirs/download_dnb_composites.html\">VIIRS</a></td>\n",
        "      <td>NASA-NOAA-DoD</td>\n",
        "      <td>April 2012 - Present</td>\n",
        "      <td>Monthly</td>\n",
        "      <td>15 arc seconds </td>\n",
        "    </tr>\n",
        "  </table>\n",
        "\n",
        "<center>\n",
        "<b>Table 1:</b> Main data sources for nighttime lights\n",
        "</center>\n",
        "\n",
        "\n",
        "\n",
        "### 3.2 Regional income and administrative boundaries\n",
        "\n",
        "Smits, Permanyer (2019) have recently compiled a database of socioeconomic indicators at the subnational level. The dataset is based on the first-level administrative regions. As an indicator of subnational GDP per capita, we use Gross National Income per capita in thousands of US dollars (2011 PPP). We utilize version 4.0 of the database, which also includes a shapefile containing the boundaries of the administrative regions. All of these datasets are available from the Global Data Lab website: https://globaldatalab.org.\n",
        "\n",
        "## 4. Processing satellite nighttime images\n",
        "\n",
        "### 4.1 Importing and visualizing satellite images\n",
        "\n",
        "First, we define a start and end year as global variables. This definition restricts the study to a particular time frame, enabling us to focus on the period of interest and optimizing computation time.\n",
        "The start year and end year can take values from 1992 to 2020, and the start year should be less than the end year."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KAQQHd55XgAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bda363e3-4a74-4342-9cf1-48e6ee138b17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created folder: figures\n",
            "Created folder: tables\n",
            "Created folder: data/vector\n",
            "Created folder: data/tabular\n",
            "Created folder: data/raster\n"
          ]
        }
      ],
      "source": [
        "# Remove sample_data folder provided by Colab.\n",
        "!rm -rf sample_data\n",
        "# Define path constants\n",
        "FIGURES_DIRECTORY = \"figures\"\n",
        "TABLES_DIRECTORY = \"tables\"\n",
        "VECTOR_DIRECTORY = \"data/vector\"\n",
        "TABULAR_DIRECTORY = \"data/tabular\"\n",
        "RASTER_DIRECTORY = \"data/raster\"\n",
        "\n",
        "# Check and create folders using a loop\n",
        "for path in [\n",
        "    FIGURES_DIRECTORY,\n",
        "    TABLES_DIRECTORY,\n",
        "    VECTOR_DIRECTORY,\n",
        "    TABULAR_DIRECTORY,\n",
        "    RASTER_DIRECTORY,\n",
        "]:\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "        print(f\"Created folder: {path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MTiJdjh9NFT9"
      },
      "outputs": [],
      "source": [
        "# Defining start and end years\n",
        "START_YEAR = 2014\n",
        "END_YEAR = 2019"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bXTegynNFT9"
      },
      "source": [
        "Next, we load the vector file that contains the borders of Indian states using `geopandas`. The file is loaded into a `GeoDataFrame`, which has a column that contains geometric information in the form of polygons. This column is utilized for conducting geometric operations, such as spatial joins and intersections, as well as for visualizing the data using tools like `matplotlib`.\n",
        "\n",
        "From the vector file, we extract the bounding box of the vector file, which is the latitude and longitude extent of India. This allows us to crop the NTL images to values just for our region of interest, that is India. This step can reduce memory usage, computation time and make it easier to visualise the NTL around the region of interest.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AYxPHz1FNFT-"
      },
      "outputs": [],
      "source": [
        "# The boundaries of states of India are stored in gdf_india36.geojson. The file is loaded using the read_file function from geopandas\n",
        "map_url = \"https://gist.github.com/cmg777/19c25af8fcfe2291cfb6f9abf141d45a/raw/48e1489e97f975c5a2253d2068cf99a3c2d0cff3/gdf_india36.geojson\"\n",
        "\n",
        "polygons_files = gpd.read_file(map_url)\n",
        "\n",
        "# The bounding box of the vector file previously loaded is extracted using the total_bounds property\n",
        "polygons_files_bbox = polygons_files.total_bounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJbHGtm0w3ju",
        "outputId": "4b10391e-f0dc-4e3e-880d-d46ab5e52295"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File data/raster/VNL_v21_npp_2014_global_vcmslcfg_c202205302300.median_masked.dat.tif.gz downloaded successfully.\n",
            "File data/raster/VNL_v21_npp_2015_global_vcmslcfg_c202205302300.median_masked.dat.tif.gz downloaded successfully.\n",
            "File data/raster/VNL_v21_npp_2016_global_vcmslcfg_c202205302300.median_masked.dat.tif.gz downloaded successfully.\n",
            "File data/raster/VNL_v21_npp_2017_global_vcmslcfg_c202205302300.median_masked.dat.tif.gz downloaded successfully.\n",
            "File data/raster/VNL_v21_npp_2018_global_vcmslcfg_c202205302300.median_masked.dat.tif.gz downloaded successfully.\n",
            "File data/raster/VNL_v21_npp_2019_global_vcmslcfg_c202205302300.median_masked.dat.tif.gz downloaded successfully.\n"
          ]
        }
      ],
      "source": [
        "## Make an account at EOG: https://eogdata.mines.edu/products/register/\n",
        "USERNAME = \"ayushpatnaik@gmail.com\"  # you-email@gmail.com\n",
        "PASSWORD = \"n3zaCXM5TtZV3Hb\"  # your-password\n",
        "CLIENT_ID = \"eogdata_oidc\"\n",
        "CLIENT_SECRET = \"2677ad81-521b-4869-8480-6d05b9e57d48\"\n",
        "\n",
        "def download_link(link):\n",
        "    \"\"\"\n",
        "    Function to download image from EOG using the API\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    link : str\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    None\n",
        "\n",
        "    Notes:\n",
        "    ------\n",
        "    Downloads image in RASTER_DIRECTORY\n",
        "    \"\"\"\n",
        "    output_file = os.path.basename(link)\n",
        "    output_file = os.path.join(\n",
        "        RASTER_DIRECTORY, output_file\n",
        "    )  # Construct full path with folder\n",
        "    if os.path.isfile(output_file):\n",
        "        print(f\"File {output_file} already exists. Skipping download.\")\n",
        "        return\n",
        "\n",
        "    params = {\n",
        "        \"client_id\": CLIENT_ID,\n",
        "        \"client_secret\": CLIENT_SECRET,\n",
        "        \"username\": USERNAME,\n",
        "        \"password\": PASSWORD,\n",
        "        \"grant_type\": \"password\",\n",
        "    }\n",
        "    token_url = (\n",
        "        \"https://eogauth.mines.edu/auth/realms/master/protocol/openid-connect/token\"\n",
        "    )\n",
        "    response = requests.post(token_url, data=params)\n",
        "    access_token_dict = json.loads(response.text)\n",
        "    access_token = access_token_dict.get(\"access_token\")\n",
        "    data_url = link\n",
        "    auth = \"Bearer \" + access_token\n",
        "    headers = {\"Authorization\": auth}\n",
        "    response = requests.get(data_url, headers=headers)\n",
        "\n",
        "    with open(output_file, \"wb\") as f:\n",
        "        f.write(response.content)\n",
        "    print(f\"File {output_file} downloaded successfully.\")\n",
        "\n",
        "\n",
        "base_url = \"https://eogdata.mines.edu/nighttime_light/annual/v21/{}/\"\n",
        "\n",
        "for year in range(\n",
        "    START_YEAR, END_YEAR + 1\n",
        "):  # loop through years START_YEAR to END_YEAR\n",
        "    url = f\"https://eogdata.mines.edu/nighttime_light/annual/v21/{year}/VNL_v21_npp_{year}_global_vcmslcfg_c202205302300.median_masked.dat.tif.gz\"\n",
        "    download_link(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCN8bn6F1LWJ"
      },
      "outputs": [],
      "source": [
        "# Get the current working directory\n",
        "current_dir = os.getcwd()\n",
        "\n",
        "# Find all .gz files in the data/raster folder\n",
        "\n",
        "for file in glob.glob(os.path.join(current_dir, RASTER_DIRECTORY, \"*.gz\")):\n",
        "    with gzip.open(file, \"rb\") as compressed_file, open(\n",
        "        file[:-3], \"wb\"\n",
        "    ) as extracted_file:\n",
        "        shutil.copyfileobj(compressed_file, extracted_file)  # Stream data directly\n",
        "    os.remove(file)\n",
        "\n",
        "print(\"Successfully extracted all .gz files!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ut8Hl9gLNFT-"
      },
      "source": [
        "We utilize `rasterio` to load the NTL images of the world for the start and end years. Then, we employ the bounding box of the vector file to crop the image specifically to India.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaT5ON_pNFT-"
      },
      "outputs": [],
      "source": [
        "def load_raster(year):\n",
        "    \"\"\"\n",
        "    Load a raster file based on the provided time identifier.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    year : str\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    rasterio.io.DatasetReader\n",
        "    An opened raster file dataset ready for further operations.\n",
        "\n",
        "    Example:\n",
        "    --------\n",
        "    >>> raster_2014 = load_raster(2014)\n",
        "    >>> type(raster_2014)\n",
        "    <class 'rasterio.io.DatasetReader'>\n",
        "\n",
        "    Notes:\n",
        "    ------\n",
        "    Modify the path in the function if your file structure\n",
        "    or naming convention differs.\n",
        "    \"\"\"\n",
        "    raster_path = f\"{RASTER_DIRECTORY}/VNL_v21_npp_{year}*\"\n",
        "    return rasterio.open(glob.glob(raster_path)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHaVYa6DNFT_"
      },
      "outputs": [],
      "source": [
        "# The raster file corresponding to the start year is loaded using the open function in rasterio\n",
        "raster_file_first = load_raster(START_YEAR)\n",
        "\n",
        "# The bounding box of the vector data is used to crop the raster file\n",
        "raster_file_window_first = raster_file_first.window(*polygons_files_bbox)\n",
        "raster_file_clipped_first = raster_file_first.read(1, window=raster_file_window_first)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqvtUkAaNFT_"
      },
      "outputs": [],
      "source": [
        "# The raster file corresponding to the start year is loaded using the open function in rasterio\n",
        "raster_file_last = load_raster(END_YEAR)\n",
        "\n",
        "# The bounding box of the vector data is used to crop the raster file\n",
        "raster_file_window_last = raster_file_last.window(*polygons_files_bbox)\n",
        "raster_file_clipped_last = raster_file_last.read(1, window=raster_file_window_last)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxak-U5bNFUA"
      },
      "outputs": [],
      "source": [
        "# Initialize the GridSpec for setting up the plot structure\n",
        "RADIANCE_THRESHOLD = 20\n",
        "\n",
        "gs = GridSpec(1, 3, width_ratios=[2, 2, 0.1])\n",
        "\n",
        "fig = plt.figure(figsize=(15, 8))\n",
        "ax1 = fig.add_subplot(gs[0])\n",
        "\n",
        "first_year_plot = ax1.imshow(\n",
        "    raster_file_clipped_first,\n",
        "    extent=polygons_files_bbox[[0, 2, 1, 3]],\n",
        "    vmin=0,\n",
        "    vmax=RADIANCE_THRESHOLD,\n",
        "    cmap=\"magma\",\n",
        ")\n",
        "polygons_files.boundary.plot(ax=ax1, color=\"skyblue\", linewidth=0.4)\n",
        "ax1.set_title(f\"(a) Nighttime lights in {START_YEAR}\")\n",
        "ax1.set_axis_off()\n",
        "\n",
        "ax2 = fig.add_subplot(gs[1])\n",
        "\n",
        "last_year_plot = ax2.imshow(\n",
        "    raster_file_clipped_last,\n",
        "    extent=polygons_files_bbox[[0, 2, 1, 3]],\n",
        "    vmin=0,\n",
        "    vmax=RADIANCE_THRESHOLD,\n",
        "    cmap=\"magma\",\n",
        ")\n",
        "polygons_files.boundary.plot(ax=ax2, color=\"skyblue\", linewidth=0.4)\n",
        "ax2.set_title(f\"(a) Nighttime lights in {END_YEAR}\")\n",
        "ax2.set_axis_off()\n",
        "\n",
        "cax2 = fig.add_subplot(gs[2])\n",
        "# Add colorbar\n",
        "cbar = fig.colorbar(\n",
        "    first_year_plot, cax=cax2, label=\"Luminosity intensity (nanoWatts/sr/$cm^2$)\"\n",
        ")\n",
        "\n",
        "# Set ticks and labels with the last one as f\"{RADIANCE_THRESHOLD}+\"\n",
        "cbar.set_ticklabels(\n",
        "    [f\"{val}\" for val in cbar.get_ticks()[:-1]] + [f\"{RADIANCE_THRESHOLD}+\"]\n",
        ")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"figures/NTL.png\", dpi=300, bbox_inches=\"tight\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G9T1AQgNFT_"
      },
      "source": [
        "In Figure 1, we overlay the cropped NTL images for the start and end years. We then superimpose the state boundaries from the vector file. As expected, India exhibits a brighter appearance in the image for the end year in comparison to the start year."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0L9G7AwNFT_"
      },
      "source": [
        "### 4.2 Computing zonal statistics\n",
        "\n",
        "To conduct a meaningful comparison between NTL and subnational GDP, it is crucial to ensure that both datasets are at the same geographic scale. As subnational GDP data are available at the state level, we need to aggregate the NTL values accordingly. This can be achieved through zonal statistics, where we sum the amount of light for each state, resulting in state-level nighttime lights data. Mean, median and other operator can also be used.\n",
        "To accomplish this aggregation, we initially load the NTL images for each year of interest. Next, we define a mask function that can filter out all points outside the polygon in the raster file. Lastly, we apply the mask function to each polygon in the vector file, resulting in the summation that generates state-level nighttime light data for each year. More details about this implementation are provided in Appendix A."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8rx2tnoNFT_"
      },
      "outputs": [],
      "source": [
        "# A dataframe is initialised to store the results\n",
        "gdf_NTL = polygons_files.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "227mseMINFT_"
      },
      "outputs": [],
      "source": [
        "# Choose an operator for aggregation. In this notebook, the operator, AGGREGATE_OPERATOR, has been set to np.ma.sum.\n",
        "# Other operators can be chosen, for example, np.ma.mean and np.ma.median will compute the mean and median respectively.\n",
        "# The list of operators can be found here: https://numpy.org/doc/stable/reference/routines.ma.html\n",
        "AGGREGATE_OPERATOR = np.ma.sum\n",
        "\n",
        "\n",
        "# Define the clean_mask function outside the loop\n",
        "def geom_mask(geom, dataset, crop=True, all_touched=True):\n",
        "    masked, mask_transform = mask(\n",
        "        dataset=dataset, shapes=(geom,), crop=crop, all_touched=all_touched\n",
        "    )\n",
        "    return masked\n",
        "\n",
        "\n",
        "# A loop runs from the start year to the end year that computes the aggregate nighttime lights radiance for each state\n",
        "for year in range(START_YEAR, END_YEAR + 1):\n",
        "    # The raster file of the given year is loaded\n",
        "    raster_file = load_raster(year)\n",
        "    # The mask is applied, and then a summation is performed for computing the aggregate radiance.\n",
        "    statewise_agg_ntl = polygons_files.geometry.apply(\n",
        "        geom_mask, dataset=raster_file\n",
        "    ).apply(AGGREGATE_OPERATOR)\n",
        "\n",
        "    # The state-wise aggregate radiance of the year is stored in the data frame that was initialized earlier.\n",
        "    gdf_NTL[str(year)] = statewise_agg_ntl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MxF2F-MNFUA"
      },
      "source": [
        "<center><b>Figure 1:</b> Raster images of nighttime lights and administrative boundaries of India: Initial vs final year </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO3e7zE2NFUA"
      },
      "source": [
        "As the final step in the aggregation process, we obtain a `GeoDataFrame` in which each\n",
        "column represents the total sum of nighttime lights for each state across all years."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgJmfllYNFUA"
      },
      "outputs": [],
      "source": [
        "# gdf_NTL now contains the aggregate radiance for each year.\n",
        "gdf_NTL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QzQtJepNFUA"
      },
      "source": [
        "<center> <b>Table 2:</b> Regional nighttime light values over time </center>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_latex_table(gdf_NTL, \"tables/gdf_NTL.tex\", 10,7)"
      ],
      "metadata": {
        "id": "dqNNAYA-8k4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOawblpLNFUB"
      },
      "source": [
        "Next, we create a data frame of summary statistics of state-level nighttime lights by year."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grnxylQeNFUB"
      },
      "outputs": [],
      "source": [
        "# The summary statistics of aggregate nighttime lights is produced for each year\n",
        "gdf_NTL_summary = gdf_NTL.drop([\"geometry\", \"id\"], axis=1).describe().round(2)\n",
        "gdf_NTL_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TRA9DboNFUB"
      },
      "source": [
        "<center> <b>Table 3:</b> Descriptive statistics of regional nighttime lights </center>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gdf_NTL_summary.to_latex(), file=open(\"tables/gdf_NTL_round.tex\", \"w\"))"
      ],
      "metadata": {
        "id": "CudcG7-4F9sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnUL7dExNFUB"
      },
      "source": [
        "Next, we export the results as a geojson file, ready for potential data analysis in other software."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlDKcR_INFUB"
      },
      "outputs": [],
      "source": [
        "# The aggregate nighttime lights radiance dataframe is saved to file.\n",
        "gdf_NTL.to_file(\"data/vector/gdf_NTL.geojson\", driver=\"GeoJSON\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGi7-jqNNFUB"
      },
      "source": [
        "### 4.3 Creating panel-data structures\n",
        "\n",
        "Having successfully aggregated the nighttime lights data to the state level to align with the resolution of the subnational GDP data, we can now create panel-data structures for both datasets and merge them into a single dataset.\n",
        "\n",
        "We retrieve the state-level nighttime lights and GDP data for India, the former having been saved in the previous code cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfW3yKusNFUC"
      },
      "outputs": [],
      "source": [
        "# State level nighttime lights data is read using geopandas\n",
        "df_NTL = gpd.read_file(\"data/vector/gdf_NTL.geojson\").drop(\"geometry\", axis=1)\n",
        "# State level GDP data is loaded from a csv file\n",
        "df_GDP = pd.read_csv(\n",
        "    \"https://gist.github.com/cmg777/150c0b93ae8eb14fec9babdf4f5f8fc4/raw/2af006ed2b80cdb3ef9b6dd13ccc8a450c168765/df_GDP_India36.csv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY4rTpOLNFUC"
      },
      "source": [
        "Both datasets have been transformed into a long-form panel structure and are ready for merging into a single dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBXTOAaANFUC"
      },
      "outputs": [],
      "source": [
        "# Nighttime lights data is put in long form, which is often used for regressions\n",
        "df2_NTL = pd.melt(\n",
        "    df_NTL,\n",
        "    id_vars=[\"id\", \"region\"],\n",
        "    value_vars=[str(x) for x in range(START_YEAR, END_YEAR + 1)],\n",
        ")\n",
        "df2_NTL.columns = [\"id\", \"region\", \"year\", \"NTL\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzCbCyPSNFUC"
      },
      "outputs": [],
      "source": [
        "# Subnational GDP data is also put in long form\n",
        "df2_GDP = pd.melt(\n",
        "    df_GDP,\n",
        "    id_vars=[\"id\", \"region\"],\n",
        "    value_vars=[str(x) for x in range(START_YEAR, END_YEAR  + 1)],\n",
        ")\n",
        "df2_GDP.columns = [\"id\", \"region\", \"year\", \"GDP\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2KL6Sa3NFUC"
      },
      "outputs": [],
      "source": [
        "# Nighttime lights data is merged with the GDP data to form a single long form data from\n",
        "df = pd.merge(df2_GDP, df2_NTL, on=[\"id\", \"region\", \"year\"], how=\"inner\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k8fXdDGNFUC"
      },
      "source": [
        "Two new columns are added based on the logarithmic values of nighttime lights and GDP. To avoid calculation problems with the logarithmic values of NTL, we add a constant of 0.01."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44esZRTiNFUC"
      },
      "outputs": [],
      "source": [
        "# Columns are created for log of nighttime lights and GDP.\n",
        "LOG_OFFSET = 0.01\n",
        "df[\"lnNTL\"] = np.log(LOG_OFFSET + df[\"NTL\"])\n",
        "df[\"lnGDP\"] = np.log(LOG_OFFSET + df[\"GDP\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx_m9A5mNFUC"
      },
      "source": [
        "Finally, we have a panel-data structure with log of state-level nighttime lights and GDP.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeNWrhzNNFUD"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwQLKV5aNFUD"
      },
      "source": [
        "<center> <b>Table 4:</b> Regional GDP and nighttime lights: long-form panel dataset </center>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_latex_table(df, \"tables/df.tex\", 10,7)"
      ],
      "metadata": {
        "id": "npir4Tp4Q-vL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUzg_h_5NFUD"
      },
      "outputs": [],
      "source": [
        "# Saving the long form tabular data to a csv file\n",
        "df.to_csv(\"data/tabular/df_NTL_GDP_lnNTL_lnGDP.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4ip-KVCNFUD"
      },
      "source": [
        "For further analysis, the panel-data structure is pivoted. This new panel-data structure is a wide-form dataset that contains the following columns: id, region name, geometry, and logarithm values NTL for each year."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2HICwTCNFUD"
      },
      "outputs": [],
      "source": [
        "# Pivot panel data from long form to wide form\n",
        "df_lnNTL = df.pivot_table(\n",
        "    index=[\"id\", \"region\"], columns=\"year\", values=\"lnNTL\"\n",
        ").reset_index(drop=False)\n",
        "# Make sure the column names are strings\n",
        "df_lnNTL.columns = df_lnNTL.columns.astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BY4a3nZwNFUE"
      },
      "outputs": [],
      "source": [
        "# Merge with polygons_files\n",
        "gdf_lnNTL = pd.merge(\n",
        "    polygons_files,\n",
        "    df_lnNTL,\n",
        "    left_on=[\"id\", \"region\"],\n",
        "    right_on=[\"id\", \"region\"],\n",
        "    how=\"inner\",\n",
        ")\n",
        "gdf_lnNTL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHa4V254NFUE"
      },
      "source": [
        "<center> <b>Table 5:</b> Regional nighttime lights: wide-form panel dataset </center>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_latex_table(gdf_lnNTL, \"tables/gdf_lnNTL.tex\", 10,7)"
      ],
      "metadata": {
        "id": "xrL0HsVDS_O7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZbHovNUNFUE"
      },
      "source": [
        "The resulting dataset is saved and will be used in the next section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CXDjZMeNFUE"
      },
      "outputs": [],
      "source": [
        "# Writing the geo data frame of state wise log nighttime lights to a geojson file.\n",
        "gdf_lnNTL.to_file(\"data/vector/gdf_lnNTL.geojson\", driver=\"GeoJSON\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-jJaUOZNFUE"
      },
      "source": [
        "Similarly, we construct a wide-form panel dataset for the logarithmic values of GDP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKw-GlDVNFUE"
      },
      "outputs": [],
      "source": [
        "# Pivot panel data from long form to wide form\n",
        "df_lnGDP = df.pivot_table(\n",
        "    index=[\"id\", \"region\"], columns=\"year\", values=\"lnGDP\"\n",
        ").reset_index(drop=False)\n",
        "# Make sure the column names are strings\n",
        "df_lnGDP.columns = df_lnGDP.columns.astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFxLZ-1XNFUF"
      },
      "outputs": [],
      "source": [
        "# Merge with polygons_files\n",
        "gdf_lnGDP = pd.merge(\n",
        "    polygons_files,\n",
        "    df_lnGDP,\n",
        "    left_on=[\"id\", \"region\"],\n",
        "    right_on=[\"id\", \"region\"],\n",
        "    how=\"inner\",\n",
        ")\n",
        "gdf_lnGDP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKVdI1vTNFUF"
      },
      "source": [
        "<center> <b>Table 6:</b> Regional GDP: wide-form panel dataset</center>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_latex_table(gdf_lnNTL, \"tables/gdf_lnGDP.tex\", 10,7)"
      ],
      "metadata": {
        "id": "lA4mwAZ107gD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7Dhc3HcNFUF"
      },
      "outputs": [],
      "source": [
        "# Writing the geo data frame of state wise log GDP to a geojson file.\n",
        "\n",
        "gdf_lnGDP.to_file(\"data/vector/gdf_lnGDP.geojson\", driver=\"GeoJSON\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWLAaOjfNFUF"
      },
      "source": [
        "##  5. Analyzing nighttime lights and GDP\n",
        "### 5.1 Exploring space-time patterns\n",
        "#### 5.1.1 Choropleth maps\n",
        "\n",
        "Based on the previously constructed panel-data structures (`gdf_lnNTL` and `gdf_lnGDP`), we construct comparative choropleth maps for (log) nighttime lights and GDP. The `explore()` function of the Geopandas package allows us to easily construct interactive maps. In addition, consistent with the `Mapclassify` package, multiple classification schemes are available. For example, in Figures 2 and 3, we use a boxplot classification to understand the spatial distribution of NTL and GDP in 2013. We can easily identify where the regions below and above the median are located. In addition, we can identify and compare the spatial clusters of both distributions. Although there are large similarities in these two variables, their spatial classification is not identical. For example, the region of Madhya Pradesh, which is located in the center of India, is classified in the highest quantile in terms of its luminosity, but it is below the 75th percentile in terms of GDP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVXUQTs4NFUF"
      },
      "outputs": [],
      "source": [
        "# The explore function of geopandas creates an interactive choroplet map\n",
        "gdf_lnNTL.explore(\n",
        "    column=str(START_YEAR),\n",
        "    tooltip=[\"region\", str(START_YEAR)],\n",
        "    scheme=\"BoxPlot\",  # Quantiles, EqualInterval, BoxPlot, FisherJenks\n",
        "    cmap=\"magma\",  # hot, cividis, plasma, magma, inferno, coolwarm, viridis\n",
        "    legend=True,\n",
        "    tiles=\"CartoDB dark_matter\",  # CartoDB dark_matter OpenStreetMap, Stamen Terrain, Stamen Toner, Stamen Watercolor, CartoDB positron, CartoDB dark_mat,\n",
        "    style_kwds=dict(color=\"darkgrey\", weight=0.8),\n",
        "    legend_kwds=dict(colorbar=False),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUOBQbR0NFUF"
      },
      "source": [
        "<center><b>Figure 2:</b> Distribution of (log) NTL in 2013</center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgjqEhdKNFUF"
      },
      "outputs": [],
      "source": [
        "# The explore function of geopandas creates an interactive choroplet map of log GDP\n",
        "\n",
        "gdf_lnGDP.explore(\n",
        "    column=str(END_YEAR),\n",
        "    tooltip=[\"region\", str(END_YEAR)],\n",
        "    scheme=\"BoxPlot\",  # Quantiles, EqualInterval, BoxPlot, FisherJenks\n",
        "    cmap=\"magma\",  # hot, cividis, plasma, magma, inferno, coolwarm, viridis\n",
        "    legend=True,\n",
        "    tiles=\"CartoDB dark_matter\",  # CartoDB dark_matter OpenStreetMap, Stamen Terrain, Stamen Toner, Stamen Watercolor, CartoDB positron, CartoDB dark_mat,\n",
        "    style_kwds=dict(color=\"darkgrey\", weight=0.8),\n",
        "    legend_kwds=dict(colorbar=False),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1V-ZD1CaNFUG"
      },
      "source": [
        "<center><b>Figure 3:</b> Distribution of (log) GDP in 2013</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qjRLebQNFUG"
      },
      "source": [
        "Static choropleth maps are also produced, allowing them to be included in non-HTML reports. In Figures 4 and 5, we show how the spatial distributions of NTL and GDP have changed over time. For that purpose, we keep the classification of the initial year constant (except for the minimum and maximum values). In both distributions, we can clearly observe inter-quantile mobility over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OxWhra4NFUG"
      },
      "outputs": [],
      "source": [
        "# Static plot of (log) NTL for the initial and final year\n",
        "\n",
        "# A figure is initialized\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
        "\n",
        "# The plot of the start year is added\n",
        "gdf_lnNTL.plot(\n",
        "    column=str(START_YEAR),\n",
        "    scheme=\"BoxPlot\",\n",
        "    cmap=\"magma\",\n",
        "    edgecolor=\"darkgrey\",\n",
        "    legend=True,\n",
        "    ax=axes[0],\n",
        "    legend_kwds={\"bbox_to_anchor\": (0.88, 0.30)},\n",
        ")\n",
        "cx.add_basemap(\n",
        "    ax=axes[0],\n",
        "    crs=gdf_lnNTL.crs.to_string(),\n",
        "    source=cx.providers.CartoDB.DarkMatterNoLabels,\n",
        "    attribution=False,\n",
        ")\n",
        "\n",
        "# The plot of the end year is added.\n",
        "gdf_lnNTL.plot(\n",
        "    column=str(END_YEAR),\n",
        "    scheme=\"user_defined\",\n",
        "    classification_kwds={\"bins\": [3.99, 9.93, 12.48, 13.89]},\n",
        "    cmap=\"magma\",\n",
        "    edgecolor=\"darkgrey\",\n",
        "    legend=True,\n",
        "    ax=axes[1],\n",
        "    legend_kwds={\"bbox_to_anchor\": (0.88, 0.30)},\n",
        ")\n",
        "cx.add_basemap(\n",
        "    ax=axes[1],\n",
        "    crs=gdf_lnNTL.crs.to_string(),\n",
        "    source=cx.providers.CartoDB.DarkMatterNoLabels,\n",
        "    attribution=False,\n",
        ")\n",
        "\n",
        "plt.tight_layout()\n",
        "axes[0].axis(\"off\")\n",
        "axes[1].axis(\"off\")\n",
        "axes[0].set_title(\"(a) Log of NTL in \" + str(START_YEAR))\n",
        "axes[1].set_title(\"(b) Log of NTL in \" + str(END_YEAR))\n",
        "\n",
        "plt.savefig(\"figures/fig_map_lnNTL.png\", dpi=300, bbox_inches=\"tight\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_IXVv3aNFUG"
      },
      "source": [
        "<center><b>Figure 4:</b> Distribution of (log) nighttime lights: 2013 vs 2019</center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSrXthjDNFUG"
      },
      "outputs": [],
      "source": [
        "# Static plot of (log) GDP for the initial and final year\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
        "\n",
        "# plot for the start year is added.\n",
        "gdf_lnGDP.plot(\n",
        "    column=str(START_YEAR),\n",
        "    scheme=\"BoxPlot\",\n",
        "    cmap=\"magma\",\n",
        "    edgecolor=\"darkgrey\",\n",
        "    legend=True,\n",
        "    ax=axes[0],\n",
        "    legend_kwds={\"bbox_to_anchor\": (0.88, 0.30)},\n",
        ")\n",
        "cx.add_basemap(\n",
        "    ax=axes[0],\n",
        "    crs=gdf_lnGDP.crs.to_string(),\n",
        "    source=cx.providers.CartoDB.DarkMatterNoLabels,\n",
        "    attribution=False,\n",
        ")\n",
        "\n",
        "# plot for the end year is added.\n",
        "gdf_lnGDP.plot(\n",
        "    column=str(END_YEAR),\n",
        "    scheme=\"user_defined\",\n",
        "    classification_kwds={\"bins\": [12.43, 16.70, 18.57, 19.54]},\n",
        "    cmap=\"magma\",\n",
        "    edgecolor=\"darkgrey\",\n",
        "    legend=True,\n",
        "    ax=axes[1],\n",
        "    legend_kwds={\"bbox_to_anchor\": (0.88, 0.30)},\n",
        ")\n",
        "cx.add_basemap(\n",
        "    ax=axes[1],\n",
        "    crs=gdf_lnGDP.crs.to_string(),\n",
        "    source=cx.providers.CartoDB.DarkMatterNoLabels,\n",
        "    attribution=False,\n",
        ")\n",
        "\n",
        "plt.tight_layout()\n",
        "axes[0].axis(\"off\")\n",
        "axes[1].axis(\"off\")\n",
        "axes[0].set_title(\"(a) Log GDP in \" + str(START_YEAR))\n",
        "axes[1].set_title(\"(b) Log GDP in \" + str(END_YEAR))\n",
        "plt.savefig(\"figures/fig_map_lnGDP.png\", dpi=300, bbox_inches=\"tight\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjBgs8XSNFUH"
      },
      "source": [
        "#### 5.1.2 Regional time series\n",
        "\n",
        "In this section, we study the evolution of nighttime lights (NTL) for each region. As we also have the time series of GDP, we compare their trends and have a first visual validation of the usefulness of NTL for predicting economic activity over time. The plotting library `Plotly Express` is particularly useful for exploring time series when the data is organized as a long-form dataframe. In the code below, we use the previously constructed dataframe (`df`), which contains both NTL and GDP data. After indicating the `x` and `y` variables, we only need to use the argument `color` to identify the regions. After generating the `Plotly` object, to save the results as a static image, we can also use the `write_image( )` method. To generate a similar graph for GDP, we only need to change one argument: `y = \"lnGDP\"`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OMsGl-ZNFUH"
      },
      "outputs": [],
      "source": [
        "# Regional time series of (log) nighttime lights\n",
        "fig_ts_lnNTL = px.line(df, x=\"year\", y=\"lnNTL\", color=\"region\")\n",
        "fig_ts_lnNTL.show(renderer=\"colab\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l92hnlZJNFUH"
      },
      "source": [
        "<center> <b>Figure 6:</b> Evolution of (log) nighttime lights in each region </center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXn-cQxENFUH"
      },
      "outputs": [],
      "source": [
        "# Save figure as PNG file\n",
        "fig_ts_lnNTL.write_image(\"figures/fig_ts_lnNTL.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_lnb2QJNFUH"
      },
      "outputs": [],
      "source": [
        "# Regional time series of log GDP using Plotly.\n",
        "fig_ts_lnGDP = px.line(df, x=\"year\", y=\"lnGDP\", color=\"region\")\n",
        "fig_ts_lnGDP.show(renderer=\"colab\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2iGDfepNFUI"
      },
      "source": [
        "<center> <b>Figure 7:</b>Evolution of (log) GDP in each region </center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDhjKuvHNFUI"
      },
      "outputs": [],
      "source": [
        "# Save figure as PNG file\n",
        "fig_ts_lnGDP.write_image(\"figures/fig_ts_lnGDP.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eDp9xXaNFUI"
      },
      "source": [
        "Figures 6 and 7 show the time series of NTL and GDP, respectively, on a regional basis. A preliminary visual examination reveals the similarities and differences between these two variables in each region. In certain regions, the NTL trends exhibit greater fluctuations than the GDP trends. Due to the possibility of measurement errors in earth observation data, such fluctuations warrant further attention and data processing. For long-term analyses, it may be appropriate to use a time-series filter to eliminate short-term fluctuations. Despite this, a preliminary visual assessment can provide useful information and can be performed effortlessly using the `Plotly Express` library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bni5C4RYNFUI"
      },
      "source": [
        "#### 5.1.3 Scatter plot with linear fit\n",
        "\n",
        "To study the relationship between nighttime lights (NTL) and GDP, we use the interactive scatterplot from the `Plotly Express` library. In addition to the data frame, the x-axis, and the y-axis, the function `px.scatter()` allows us to specify other informative arguments, among them: hover on name, text on selected observations, animation frame, and trend line. The animation frame and the trend line options are informative when analyzing longitudinal data. When activated, we can fit a regression line for each time period. Also, when hovering on the regression line, we can easily get regression statistics such as R-Squared, regression coefficients, and predicted y values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptppp7DDNFUI"
      },
      "outputs": [],
      "source": [
        "# Interactive scatter plot and regression line of the NTL-GDP relationship\n",
        "\n",
        "df_selected_year = df[df['year'].astype(int) == START_YEAR]\n",
        "\n",
        "N_LABELLED_REGIONS = 6\n",
        "\n",
        "quantiles = np.linspace(0, 1, N_LABELLED_REGIONS + 1)\n",
        "quantiles = df_selected_year['lnNTL'].quantile(quantiles)\n",
        "\n",
        "# Function to find the closest value to a given quantile\n",
        "def find_closest_value(quantile_val):\n",
        "    return df_selected_year.iloc[(df_selected_year['lnNTL'] - quantile_val).abs().argsort()[:1]]\n",
        "\n",
        "# Find closest regions to the quantiles\n",
        "selected_regions = pd.concat([find_closest_value(quantile) for quantile in quantiles])\n",
        "\n",
        "region_text = selected_regions[\"region\"]\n",
        "\n",
        "# Create a new column 'selected_region' in df based on the condition\n",
        "df['selected_regions'] = df['region'].where(df['region'].isin(region_text), pd.NA)\n",
        "\n",
        "fig_sc_lnNTL_lnGDP = px.scatter(\n",
        "    data_frame=df,\n",
        "    x=\"lnNTL\",\n",
        "    y=\"lnGDP\",\n",
        "    range_x = [2, 16.5],\n",
        "    range_y = [12, 22],\n",
        "    hover_name=\"region\",\n",
        "    text=\"selected_regions\",\n",
        "    animation_frame=\"year\",\n",
        "    trendline=\"ols\",\n",
        ")\n",
        "\n",
        "fig_sc_lnNTL_lnGDP.update_traces(textposition=\"top center\")\n",
        "fig_sc_lnNTL_lnGDP.show(renderer=\"colab\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qULtRgdSNFUJ"
      },
      "source": [
        "<center> <b>Figure 8:</b> Relationship between nighttime lights and GDP </center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEiMIMWcNFUJ"
      },
      "outputs": [],
      "source": [
        "# Save figure as PNG file\n",
        "fig_sc_lnNTL_lnGDP.write_image(\"figures/fig_sc_lnNTL_lnGDP.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GK7w7MkbNFUJ"
      },
      "source": [
        "Figure 8 shows a strong linear relationship between (log) NTL and GDP. In the year 2013, NTL explained 91 percent of the regional variation in GDP. Over time, however, the predictive power of NTL has decreased. By 2019, NTL explained 81 percent of regional GDP. The regression coefficient of NTL in 2013 was 0.82, indicating that a ten percent increase in NTL is associated with an 8.2 percent increase in GDP. Over time, this coefficient has slightly increased. By 2019, a ten percent increase in NTL is associated with an 8.6 percent increase in GDP. Taken together, these results indicate that, on a year-by-year basis, nighttime lights are a useful proxy for economic activity.\n",
        "\n",
        "### 5.2 Predicting GDP with nightlights\n",
        "\n",
        "To evaluate the usefulness of nighttime lights (NTL) for predicting economic activity (GDP), let us consider the following panel-data model:\n",
        "\n",
        "$\\log (GDP)_{it} =  \\beta \\log (NTL)_{it} + \\mu_i + \\varphi_t + \\varepsilon_{it}, $ (1)\n",
        "\n",
        "where $i$ indexes the regional economies,  $t$ indexes the years, $\\mu_i$ is a region-specific  effect,  $\\varphi_t$ is a year-specific effect, and $\\varepsilon_{it}$ is the term of random disturbance. Region specific effects, $\\mu_i$, capture the influence of unobserved factors that are constant over time. Time specific effects, $\\varphi_t$, capture the influence of unobserved factors that change over time but are common between regions. The most important parameter in this model is $\\beta$, which summarizes the relation between GDP and nighttime lights (NTL). Given the logarithmic specification of the model, the parameter $\\beta$ indicates by what percentage GDP changes when the NTL changes by 1\\%. However, the specification of Equation 1 does not imply that NTL causes GDP. The parameter $\\beta$ only has a predictive interpretation.\n",
        "\n",
        "There are multiple ways to estimate the parameter $\\beta$. Let us consider the following three basic cases:\n",
        "\n",
        "$\\log (GDP)_{it} =  \\beta_{\\text{Pooled}} \\log (NTL)_{it} + \\mu + \\varepsilon_{it}, $ (2)\n",
        "\n",
        "$\\overline{\\log (GDP)_{i}}  =  \\beta_{\\text{Between}} \\overline{\\log (NTL)_{i}} + \\mu_i + \\overline{\\varepsilon_{i}},\n",
        "$ (3)\n",
        "\n",
        "$\\log (GDP)_{it} - \\overline{\\log (GDP)_{i}} =  \\beta_{\\text{Within}} \\left[\\log (NTL)_{it} - \\overline{\\log (NTL)_{i}} \\right] + \\varphi_t + \\varepsilon_{it} - \\overline{\\varepsilon_{i}}, $ (4)\n",
        "\n",
        "\n",
        "The simplest estimation of $\\beta$ is based on the so-called \"pooled\" estimator, $\\beta_{\\text{Pooled}}$. In this setting (Equation 2), time-specific effects are set to zero and all regions share a common intercept $\\mu$. The parameter $\\beta_{\\text{Pooled}}$ indicates that--for all regional observations--an increase in NTL of 1\\% leads to a $\\beta_{\\text{Pooled}}$ \\% expected increase in GDP. This model implies that we can expect the same effect of NTL on GDP if there is a 1\\% difference between regions or a 1\\% increase within a region. Thus, an important limitation of Equation 2 is that we cannot disentangle the usefulness of NTL data to predict cross-sectional differences or time series changes in GDP.\n",
        "\n",
        "The \"between\" and \"within\" estimators are commonly used to evaluate the usefulness of NTL data for predicting GDP differences and changes within regions, respectively (Gibson, Boe-Gibson, 2021; Zhang, Gibson, 2022). In Equation 3, the (log) values of GDP and NTL are time averaged, and the model is estimated using standard cross-sectional methods. The parameter $\\beta_{\\text{Between}}$ indicates the effect on GDP when NTL changes between regions. In Equation 4, Equation 3 is subtracted from Equation 1, and, by doing so, unobservable region-specific effects ($\\mu_i$) are removed from the estimation.\n",
        "The parameter $\\beta_{\\text{Within}}$ indicates the effect on GDP when NTL changes within regions.\n",
        "\n",
        "The Linearmodels package allows us to estimate a variety of panel-data models. We can easily compare the previously described estimations. Consistent with the previous literature (Gibson, Boe-Gibson, 2021; Zhang, Gibson, 2022), the results of Table 7 show that the predictive capabilities of NTL vary greatly depending on the type of data structure. The results of the \"between estimator\" are encouraging in terms of statistical significance and predictive power. NTL data predict about 86\\% of the variation in GDP data. The regression coefficient indicates that a 10\\% increase in NTL is associated with an 8.87\\% increase in GDP. In contrast, the results of the \"within estimator\" do not show a statistically significant relationship between NTL and GDP. Based on these results, nighttime lights are better at predicting cross-sectional differences than changes in time series."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBKK8wIVNFUJ"
      },
      "outputs": [],
      "source": [
        "# Reading the panel data csv that contains statewise GDP and aggregate nighttime lights.\n",
        "df_panel = pd.read_csv(\"data/tabular/df_NTL_GDP_lnNTL_lnGDP.csv\").set_index(\n",
        "    [\"region\", \"year\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shTZDBKANFUJ"
      },
      "outputs": [],
      "source": [
        "# Performing panel data regressions to find the relationship between nighttime lights and subnational GDP.\n",
        "table = {\n",
        "    \"(1) Pooled\": PooledOLS.from_formula(\n",
        "        formula=\"lnGDP ~ 1 + lnNTL\", data=df_panel\n",
        "    ).fit(cov_type=\"clustered\"),\n",
        "    \"(2) Between\": BetweenOLS.from_formula(\n",
        "        formula=\"lnGDP ~ 1 + lnNTL\", data=df_panel\n",
        "    ).fit(cov_type=\"clustered\"),\n",
        "    \"(3) Within\": PanelOLS.from_formula(\n",
        "        formula=\"lnGDP ~ 1 + lnNTL + EntityEffects + TimeEffects\", data=df_panel\n",
        "    ).fit(cov_type=\"clustered\"),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTFLp3d0NFUJ"
      },
      "outputs": [],
      "source": [
        "# Generating a summary table of the regressions.\n",
        "compare(table).summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yd3wGdjNFUK"
      },
      "source": [
        "\n",
        "<center> <b>Table 7:</b> The relationship between NTL and GDP </center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AflDHZ2NFUK"
      },
      "outputs": [],
      "source": [
        "# Saving the table in tex format\n",
        "print(compare(table).summary.as_latex(), file=open(\"tables/panel_regression.tex\", \"w\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrpY6dAGNFUK"
      },
      "source": [
        "### 5.3 Comparing regional inequality dynamics: GDP vs nightlights\n",
        "\n",
        "Inter-regional inequality is commonly identified as an important driver of socioeconomic instabilities, civil unrest, and political polarization (Ezcurra, 2019; Rodr ́ıguez-Pose, 2018). As a proxy of economic activity, nighttime lights data are also used to understand regional inequality and its dynamics (Lessmann, Seidel, 2017; Mendez, Santos-Marquez, 2021; Mveyange, 2018). In this section, we compare the evolution of regional inequality through the lens of GDP and NTL. For this purpose, we use two well-known inequality indicators: the Gini index and the Theil index.\n",
        "The `inequality` package allows us to estimate both the Gini and Theil indexes. As we want to measure regional inequality for each year, we first need to define a function that measures regional inequality for each of the year columns of our dataset. Before applying these functions, we need to define a string-type vector containing the time horizon of our analysis. The following code accomplishes these tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUe-uNptNFUK"
      },
      "outputs": [],
      "source": [
        "# Defining a function to return the Gini coefficient of a data frame column\n",
        "def gini_by_col(column):\n",
        "    return inequality.gini.Gini(column.values).g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tgMl1WhNFUK"
      },
      "outputs": [],
      "source": [
        "# Defining a function to return the Their index of a data frame column\n",
        "def theil_by_col(column):\n",
        "    return inequality.theil.Theil(column.values).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQnO2bUlNFUK"
      },
      "outputs": [],
      "source": [
        "# Defining time index for the analysis\n",
        "years = np.arange(START_YEAR, END_YEAR + 1).astype(str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVXI-hXENFUK"
      },
      "source": [
        "Next, we apply the functions defined above to the wide data frames: `gdf_lnGDP` and `gdf_lnNTL`. Four new data frames are created (`gini_lnGDP`, `gini_lnNTL`, `theil_lnGDP`, `theil_lnNTL`), each with a time index and an inequality index. These new data frames can easily allow for further data processing or visualization of the evolution of regional inequality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOCUy9vmNFUK"
      },
      "outputs": [],
      "source": [
        "# Computing Gini index for each column of the data frame\n",
        "gini_lnGDP = gdf_lnGDP[years].apply(gini_by_col, axis=0).to_frame(\"Gini_lnGDP\")\n",
        "gini_lnNTL = gdf_lnNTL[years].apply(gini_by_col, axis=0).to_frame(\"Gini_lnNTL\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y40OOat7NFUL"
      },
      "outputs": [],
      "source": [
        "# Computing Theil index for each column of the data frame\n",
        "theil_lnGDP = gdf_lnGDP[years].apply(theil_by_col, axis=0).to_frame(\"Theil_lnGDP\")\n",
        "theil_lnNTL = gdf_lnNTL[years].apply(theil_by_col, axis=0).to_frame(\"Theil_lnNTL\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZLEYCQzNFUL"
      },
      "source": [
        "Figures 9 and 10 provide a comparative visualization of the evolution of regional inequality, both in terms of nightlight luminosity (NTL) and economic activity (GDP). This comparison suggests that, compared to the regional inequality of GDP, the space-time trends of luminosity report a higher level of regional inequality. Specifically, Figure 10 shows that the inequality in NTL was 1.74 times higher than the inequality in GDP in 2013. By 2019, this inequality ratio has been reduced to 1.45. From the perspective of the Theil inequality index, Figures 11 and 12 also indicate that the regional inequality in luminosity is higher than the regional inequality in GDP.\n",
        "Researchers should be careful when interpreting the differences between nighttime lights and GDP. Both types of data are subject to measurement errors. In particular, in the context of developing countries, GDP data can suffer from incomplete coverage, price distortions, and political distortions. On the one hand, nighttime lights can suffer from calibration, blurring, and saturation errors. Therefore, understanding the magnitude of these errors is crucial when drawing conclusions from the analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7oux-PlNFUL"
      },
      "outputs": [],
      "source": [
        "# Plotting Gini index dynamics of (log) GDP and NTL\n",
        "df_gini = pd.merge(gini_lnGDP, gini_lnNTL, left_index=True, right_index=True)\n",
        "df_gini.plot()\n",
        "plt.ylabel(\"Gini index\")\n",
        "plt.savefig(\"figures/fig_ts_gini.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYPlUMrfNFUL"
      },
      "source": [
        "<center> <b>Figure 9:</b> Regional inequality dynamics of GDP and NTL based on the Gini index</center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6rYB2fSNFUL"
      },
      "outputs": [],
      "source": [
        "# Plotting the inequality ratio (NTL/GDP) based on the Gini index\n",
        "df_gini[\"Gini_Ratio\"] = df_gini[\"Gini_lnNTL\"] / df_gini[\"Gini_lnGDP\"]\n",
        "df_gini[\"Gini_Ratio\"].plot()\n",
        "plt.ylabel(\"Gini Log NTL / Gini Log GDP\")\n",
        "plt.savefig(\"figures/fig_ts_giniRatio.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KO8uv6g3NFUM"
      },
      "source": [
        "<center> <b>Figure 10:</b> Gini-based inequality ratio between NTL and GDP</center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkVoT11QNFUM"
      },
      "outputs": [],
      "source": [
        "# Plotting Theil index dynamics of (log) GDP and NTL\n",
        "df_theil = pd.merge(theil_lnGDP, theil_lnNTL, left_index=True, right_index=True)\n",
        "df_theil.plot()\n",
        "plt.ylabel(\"Theil index\")\n",
        "plt.savefig(\"figures/fig_ts_theil.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hc_9DJH7NFUM"
      },
      "source": [
        "<center> <b>Figure 11:</b> Regional inequality dynamics of GDP and NTL based on the Theil index</center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-uPN_T-NFUM"
      },
      "outputs": [],
      "source": [
        "# Plotting the inequality ratio (NTL/GDP) based on the Gini index\n",
        "df_theil[\"Theil_Ratio\"] = df_theil[\"Theil_lnNTL\"] / df_theil[\"Theil_lnGDP\"]\n",
        "df_theil[\"Theil_Ratio\"].plot()\n",
        "plt.ylabel(\"Theil Log NTL / Theil Log GDP\")\n",
        "plt.savefig(\"figures/fig_ts_theilRatio.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JelgDTmnNFUM"
      },
      "source": [
        "<center><b>Figure 12:</b> Theil-based inequality ratio between NTL and GDP</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VL4R2Sx_NFUM"
      },
      "source": [
        "## 6. Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GK5VhRSsNFUN"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4WKG1eoNFUN"
      },
      "source": [
        "## 7. Concluding remarks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ew0aF6jLNFUN"
      },
      "source": [
        "Nighttime lights (NTL) data can facilitate monitoring of economic activity within and between countries. This paper presented a user-friendly notebook for analyzing satellite NTL images in a cloud-based Python environment. When using these data, one needs to carefully explore space-time patterns, as NTL may require additional cleaning and processing. When using NTL data to predict economic activity, one must note the difference between cross-sectional and time-series predictions. NTL data has been shown to perform much better with the former. Another application worth exploring is the measurement of regional inequality dynamics. Using multiple inequality measures is recommended to confirm regional inequality trends."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XVocMFkNFUN"
      },
      "source": [
        "## References\n",
        "\n",
        "1. Bresenham JE (1965) Algorithm for computer control of a digital plotter. IBM Systems journal 4[1]: 25–30\n",
        "2. Chen X, Nordhaus WD (2011) Using luminosity data as a proxy for economic statistics. Proceedings of the National Academy of Sciences 108[21]: 8589–8594\n",
        "3. Elvidge CD, Baugh K, Zhizhin M, Hsu FC, Ghosh T (2017) VIIRS night-time lights. International Journal of Remote Sensing 38[21]: 5860–5879\n",
        "4. Elvidge CD, Baugh KE, Zhizhin M, Hsu FC (2013) Why VIIRS data are superior to dmsp for mapping nighttime lights. Proceedings of the Asia-Pacific Advanced Network 35[0]: 62\n",
        "5. Ezcurra R (2019) Interregional inequality and civil conflict: Are spatial disparities a threat to stability and peace? Defence and Peace Economics 30[7]: 759–782\n",
        "6. Gibson J, Boe-Gibson G (2021) Nighttime Lights and County-Level Economic Activity in the United States : 2001 to 2019. (May). CrossRef.\n",
        "7. Henderson JV, Storeygard A, Weil DN (2012) Measuring economic growth from outer space. American economic review 102[2]: 994–1028\n",
        "8. Lessmann C, Seidel A (2017) Regional inequality, convergence, and its determinants – A view from outer space. European Economic Review 92[Nov]: 110–132. CrossRef.\n",
        "9. Li X, Zhou Y, Zhao M, Zhao X (2020) A harmonized global nighttime light dataset 1992–2018. Scientific data 7[1]: 1–9\n",
        "10. Mendez C, Santos-Marquez F (2021, December) Regional convergence and spatial dependence across subnational regions of ASEAN: Evidence from satellite nighttime light data. Regional Science Policy & Practice 13[6]: 1750–1777. CrossRef.\n",
        "11. Mveyange A (2018) Measuring and Explaining Patterns of Spatial Income Inequality from Outer Space Evidence from Africa. World Bank Working Paper 8484[June]\n",
        "12. Rodr ́ıguez-Pose A (2018) The revenge of the places that don’t matter (and what to do about it). Cambridge journal of regions, economy and society 11[1]: 189–209\n",
        "13. Rom ́an MO, Wang Z, Sun Q, Kalb V, Miller SD, Molthan A, Schultz L, Bell J, Stokes EC, Pandey B et al. (2018) Nasa’s black marble nighttime lights product suite. Remote Sensing of Environment 210: 113–143\n",
        "14. Rowe F, Maier G, Arribas-Bel D, Rey SJ (2020) The potential of notebooks for scientific publication: Reproducibility, and dissemination. REGION 7[3]\n",
        "15. Smits J, Permanyer I (2019) The subnational human development database. Scientific data 6[1]: 1–15\n",
        "16. Sutton PC, Elvidge CD, Ghosh T et al. (2007) Estimation of gross domestic product at sub-national scales using nighttime satellite imagery. International Journal of Ecological Economics & Statistics 8[S07]: 5–21\n",
        "17. Zhang X, Gibson J (2022) Using multi-source nighttime lights data to proxy for county-level economic activity in china from 2012 to 2019. Remote Sensing 14[5]: 1282\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YejoBxxNFUN"
      },
      "source": [
        "## A. Zonal statistics\n",
        "\n",
        "### A.1 Main logic\n",
        "\n",
        "Let us consider the code inside this loop:\n",
        "\n",
        "```python\n",
        "for year in range(START_YEAR, END_YEAR + 1):\n",
        "    # The raster file of the given year is loaded\n",
        "    raster_file = load_raster(year)\n",
        "\n",
        "    # The mask is applied, and then the aggregator operation is performed for computing the aggregate radiance.\n",
        "    statewise_agg_ntl = polygons_files.geometry.apply(geom_mask, dataset=raster_file).apply(AGGREGATE_OPERATOR)\n",
        "\n",
        "    # The state-wise aggregate radiance of the year is stored in the data frame that was initialized earlier.\n",
        "    gdf_NTL[str(year)] = statewise_agg_ntl\n",
        "```\n",
        "\n",
        "In particular, let us evaluate last expression:\n",
        "```python\n",
        "polygons_files.geometry.apply(geom_mask, dataset=raster_file).apply(AGGREGATE_OPERATOR)\n",
        "```\n",
        "The `apply` method is used to apply a function on all elements of a column of a data frame. This column contains the polygons of states of India. First, we want to apply the `mask` function from `rasterio` to return a matrix corresponding to a raster file, which has `nodata` at all locations outside the polygons of the states.\n",
        "\n",
        "```python\n",
        "def geom_mask(geom, dataset, crop=True, all_touched=True):\n",
        "    masked, mask_transform = mask(dataset=dataset, shapes=(geom,), crop=crop, all_touched=all_touched)\n",
        "    return masked\n",
        "```\n",
        "\n",
        "For example:\n",
        "```python\n",
        "geom_mask(polygons_files.geometry[0])\n",
        "```\n",
        "Applies to the first polygon and returns a matrix with `nodata` outside the first polygon; hence\n",
        "```python\n",
        "polygons_files.geometry.apply(geom_mask)\n",
        "```\n",
        "Applies to all polygons.\n",
        "\n",
        "Second, after attaining the list of matrices with `nodata` outside the polygons, we want to apply the `AGGREGATOR_OPERATOR` to get the aggregate the light inside the polygons.\n",
        "\n",
        "For example:\n",
        "```python\n",
        "AGGREGATE_OPERATOR(geom_mask(polygons_files.geometry[0]))\n",
        "```\n",
        "Since `AGGREGATE_OPERATOR = np.ma.sum` (by default), this returns the sum of light of the first polygon, hence\n",
        "```python\n",
        "polygons_files.geometry.apply(geom_mask).apply(AGGREGATE_OPERATOR)\n",
        "```\n",
        "Returns the sum of light of all polygons.\n",
        "\n",
        "### A.2 geom_mask function\n",
        "We want to apply the `mask` function from `rasterio` on all elements of a `pandas` data frame column using `apply`, however, we need to pass additional arguments. For this, we create a wrapper function called `geom_mask`, which calls `mask` and passes the additional arguments. Additionally, `mask` returns two values, we only need the first one, hence `geom_mask` is used to select only one.\n",
        "\n",
        "#### A.2.1 Positional arguments\n",
        "The function has two positional arguments; geom and dataset.\n",
        "\n",
        "#### A.2.2 Keyword arguments\n",
        "There are two keyword arguments, `crop` and `all_touched`.\n",
        "\n",
        "The `crop = True` is essential. It is used to crop the output matrix to the extent of the polygon. This substantially reduced the memory requirement of the program.\n",
        "\n",
        "The second keyword argument, `all_touched = True` tells the mask function to include pixels which are touching boundaries. If false, the function will include a pixel only if its center is within the boundaries, or if it is selected by Bresenham (1965) line algorithm. For most polygons in our case, `all_touched = False` will produce similar results. The difference would be noticeable for states that contain islands.\n",
        "\n",
        "### A.3 For loop\n",
        "The iterator in the loop is used for two reasons.\n",
        "First, it is used to open the raster file corresponding to a year.\n",
        "```python\n",
        "raster_file = load_raster(year)\n",
        "```\n",
        "Second, it is used to create a column to store the state-wise sum of lights\n",
        "```python\n",
        "gdf_NTL[str(year)] = statewise_agg_ntl\n",
        "```\n",
        "Hence, for each raster file, the state-wise sum of lights is computed and stored in a column named year.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URjoyAtRNFUO"
      },
      "source": [
        "## B. Folder structure\n",
        "\n",
        "The notebook's root directory is organized into three primary folders: `data`, `figures`, and `tables`. These folders are created during the execution of the notebook.\n",
        "\n",
        "- **data:** Contains all input data that is downloaded during the execution of the notebook.\n",
        "  - *raster:* Contains the VIIRS nighttime lights raster files.\n",
        "  - *tabular:* Contains state-level GDP data for India (`df_GDP_India36.csv`), used as ground truth. During processing, the file `df_NTL_GDP_lnNTL_lnGDP.csv` is saved in this directory. It contains a dataframe with logs of aggregate nighttime lights and GDP of each state from the start year to end year.\n",
        "  - *vector:* Contains the geojson files. `gdf_india36.geojson`, which is downloaded, contains the shape of each state of India. During processing, the following files are saved: `gdf_lnGDP.geojson`, `gdf_lnNTL.geojson`, and `gdf_NTL.geojson`. These contain state-wise log GDP, log aggregate nighttime lights, and aggregate nighttime lights, respectively.\n",
        "\n",
        "- **figures:** Stores all figures generated during notebook processing.\n",
        "\n",
        "- **tables:** Stores all tables generated during notebook processing.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "e44ea0aa1b5a447ba2d7d3499e223397",
    "deepnote_persisted_session": {
      "createdAt": "2024-01-10T12:15:30.409Z"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}